---
title: "P8105 HW2"
author: "Jennifer Lee (UNI: jl2361)"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

We will first load the necessary libraries.
```{r load_libraries}
library(tidyverse)
library(readxl)
```

# Problem 1
We load in and clean the transit data, updating variable names and selecting the relevant columns. We designate our route variables as character variables, and we convert the entry variable to a logical variable using the `recode` function.

```{r}
nyctransit = read_csv('data/NYC_Transit.csv', col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, starts_with('route'), entrance_type, entry, exit_only, vending, ada) %>%
  mutate(entry = recode(entry, 'YES' = TRUE, 'NO' = FALSE))

head(nyctransit)
```

Currently, this dataset contains the following variables: `line`, `station_name`, `station_longitude`, `station_latitude`, `route`, `entrance_type`, `entry`, `exit_only`, `vending`, `ada`. There are `r nrow(nyctransit)` rows and `r ncol(nyctransit)` columns. These data are not currently tidy; the route number and route name should be variables. 

The following code chunk selects all stations identified by both name and line then the `distinct` function is applied to identify the unique stations. There are 465 distinct stations.
```{r}
nyctransit %>%
  select(station_name, line) %>%
  distinct() %>%
  nrow()
```

Using a similar strategy and applying the `filter` function, we can see that 84 stations are ADA compliant. 
```{r}
nyctransit %>%
  filter(ada == TRUE) %>%
  select(station_name, line) %>%
  distinct() %>%
  nrow()
```

To compute the proportion of station entrances / exits without vending allow entrance, we filter for those that do not allow vending. Then, we pull the `entry` variable; because this is a logical variable, taking the mean will produce the desired proportion, which is approximately 0.38 rounded to 2 decimal points.
```{r}
nyctransit %>%
  filter(vending == "NO") %>%
  pull(entry) %>%
  mean
```

Now, we reformat the dataset so that route number and route name are distinct variables by using the `pivot_longer` function to go from wide to long format. 
```{r}
nyctransitreformat = 
  pivot_longer(
    nyctransit, 
    route1:route11,
    names_to = "route_number",
    values_to = "route_name",
    names_prefix = 'route') 
```

Using a similar strategy as above, these are the code chunks used to identify that 60 stations serve the A train and that 17 of these stations are ADA compliant. 
```{r}
nyctransitreformat %>%
  filter(route_name == "A") %>%
  select(station_name, line) %>%
  distinct() %>%
  nrow()

nyctransitreformat %>%
  filter(route_name == "A", ada == TRUE) %>%
  select(station_name, line) %>%
  distinct() %>%
  nrow()
```

# Problem 2
We start with importing the Mr. Trash Wheel sheet from the excel file, selecting the desired rows and columns. We clean the dataset by updating variable names, omitting rows without dumpster-specific data, and round the number of sports balls to the nearest integer and converting this result to an integer variable using `as.integer`. The same steps are then applied to the Professor Trash Wheel sheet. 

As a final step in both datasets, we add a variable named `id` to identify each dumpster by the specific Trash Wheel and number. We then combine both datasets to form a single tidy dataset named `total_trashwheel` using the `bind_rows` function. We note a couple important things: 

* We need to change the `year` variable in the `mr_trashwheel` dataset to a numeric variable to be consistent with the `mr_professor_trashwheel` dataset in order to carry out the `bind_rows` function. 

* The `mr_professor_trashwheel` dataset does not have the `sports_balls` variable and therefore contains `NA` values once we combine the datasets.

```{r}
mr_trashwheel = read_excel('data/Trash_Wheel.xlsx', 
                                   sheet = "Mr. Trash Wheel", 
                                   range = 'A2:N550') %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    year = as.numeric(year),
    sports_balls = round(sports_balls, digit = 0) %>%
      as.integer(),
    id = paste('mr', row_number(), sep = '_')) %>%
    relocate(id) 
```

```{r}
professor_trashwheel = read_excel('data/Trash_Wheel.xlsx', 
                                   sheet = "Professor Trash Wheel", 
                                   range = 'A2:M97') %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    id = paste('prof', row_number(), sep = '_')) %>%
    relocate(id) 
```

```{r}
total_trashwheel = bind_rows(mr_trashwheel, professor_trashwheel)
head(total_trashwheel)
```

## Data Description
In the `total_trashweel` dataset, there are `r nrow(total_trashwheel)` observations of `r ncol(total_trashwheel)` variables related to litter collection for a dumpster at any given date. `r nrow(mr_trashwheel)` observations come from the `mr_trashwheel` dataset, and `r nrow(professor_trashwheel)` observations come from the `professor_trashwheel` dataset. We use the `summary` function to obtain an overview of all the datasets; the results are intentionally not displayed here to prevent cluttering. We note that data from Mr. Trash Wheel originates back to 2014 through 2022 compared to Professor Trash Wheel, which reports data from 2017 through 2022. 

```{r eval = FALSE}
summary(mr_trashwheel)
summary(professor_trashwheel)
summary(total_trashwheel)
```

These code chunks, using the `sum` and `pull` functions, were used to obtain the following computations. The total weight of trash collected by Professor Trash Wheel was 190.12 tons. The total number of sports balls collected by Mr. Trash Wheel in 2020 was 856. Of note, for the sports balls calculation, we first filtered the `mr_trashwheel` dataset for the year 2020 to create a 2020 specific dataset and then pulled the sports balls data.

```{r}
sum(pull(professor_trashwheel, weight_tons))

mr_trashwheel2020 = filter(mr_trashwheel, year == 2020) 
sum(pull(mr_trashwheel2020, sports_balls))
```

# Problem 3 
First, we load and clean the data in polsmonth.csv. We update variable names and use `separate` to break up the variable `mon` into integer variables `year`, `month`, and `day`. We replace month number with month name using `recode`, create a `president` variable taking values gop and dem using the `recode` function, and remove the `prez_dem`, `prez_gop`, and `day` variables. Of note, there are some observations in which `prez_dem` took the value of 2; these were recoded as `NA`, as we could not definitively categorize them as gop or dem. Finally, we arrange the data so that `year` and `month` are the leading columns.
```{r}
polsmonth = read_csv('data/fivethirtyeight_polsmonth.csv') %>%
  janitor::clean_names() %>%
  separate(col = mon, into = c('year', 'month', 'day'), sep = "-") %>%
  mutate(
    year = as.integer(year), 
    month = as.integer(month),
    day = as.integer(day),
    month = recode(month, '1' = "jan", '2' = "feb", '3' = "mar", '4' = "apr", '5' = "may", '6' = "jun", '7' = "jul", '8' = "aug", '9' = "sep", '10' = "oct", '11' = "nov", '12' = "dec"),
    president = recode(prez_gop, '1' = "gop", '0' = "dem")) %>%
  select(-prez_dem, -prez_gop, -day) %>%
  arrange(year, month)

head(polsmonth)
```

Second, we load and clean the data in snp.csv using a similar process. Of note, we first need to use the `as.Date` function here to specify the date format then use the `separate` function as above.
```{r}
snp = read_csv('data/fivethirtyeight_snp.csv') %>%
  janitor::clean_names() %>%
  mutate(
    date = as.Date(date, format = "%m/%d/%y")) %>%
  separate(col = date, into = c('year', 'month', 'day'), sep = "-") %>%
  mutate(
    year = as.integer(year), 
    month = as.integer(month),
    day = as.integer(day),
    month = recode(month, '1' = "jan", '2' = "feb", '3' = "mar", '4' = "apr", '5' = "may", '6' = "jun", '7' = "jul", '8' = "aug", '9' = "sep", '10' = "oct", '11' = "nov", '12' = "dec")) %>%
  select(-day) %>%
    arrange(year, month)

head(snp)
```

Third, we tidy the unemployment data so that it can be merged with the previous datasets. We switch from wide to long format, ensuring that key variables have the same names and that key variables take the same values.
```{r}
unemploy = read_csv('data/fivethirtyeight_unemployment.csv') %>%
  janitor::clean_names() %>%
  mutate(
    year = as.integer(year)) %>%
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemploy_percent") %>%
    arrange(year, month)

head(unemploy)
```

We join the datasets by merging `snp` into `polsmonth`, and merging `unemploy` into the result, using `year` and `month` as keys across datasets. We decide to use the `left_join` function specifically so that we retain all the data across datasets and do not lose any data due to missing values, particularly as the `snp` and `unemploy` datasets are not as complete as the `polsmonth` dataset. Depending on the type of analyses we are interested in, we could use the `filter` function to exclude rows lacking specific data. 
```{r}
pol_snp = left_join(polsmonth, snp, by = c("year", "month"))
unemploy_pol_snp = left_join(pol_snp, unemploy, by = c("year", "month"))

head(unemploy_pol_snp)
```

## Data Description
`polsmonth` dataset: There are `r nrow(polsmonth)` observations for `r ncol(polsmonth)` variables related to the number of national politicians who are democratic or republican at any given time. 

`snp` dataset: There are `r nrow(snp)` observations for `r ncol(snp)` variables related to the closing values of the S&P stock index on the associated date.

`unemploy` dataset: There are `r nrow(unemploy)` observations for `r ncol(unemploy)` variables related to the percentage of unemployment during the associated year.

The merged `unemploy_pol_snp` dataset contains `r nrow(unemploy_pol_snp)` observations for `r ncol(unemploy_pol_snp)` variables. We use the `summary` function to obtain an overview of this merged dataset; the results are intentionally not displayed here to prevent cluttering. This merged final dataset contains data from years 1947 to 2015 and reports all the data related to political parties, S&P stock index, and unemployment percentages arranged by year and month. 
```{r eval = FALSE}
summary(unemploy_pol_snp)
```